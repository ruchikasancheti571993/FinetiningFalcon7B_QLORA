# FinetuningFalcon7B_QLORA
Fine-tuning a model like Falcon-7B for a specific task involves adapting the pretrained model by providing task-specific labeled data. 
Here I have fine-tuned the recent Falcon-7b model on a single Google colab 
I have leveraged PEFT library from Hugging Face ecosystem, as well as QLoRA for more memory efficient finetuning.

